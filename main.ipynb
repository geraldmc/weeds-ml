{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geraldmc/torch-draft-final_project/blob/main/load_deepweeds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DeepWeeds Train, Eval, Test (Colab)*\n",
        "\n",
        "\n",
        "i) `main.ipynb`: this notebook is used to alter, train, evaluate, and test a Pytorch ResNet-50 model for k-folds. The notebook was developed to be run on Colab and includes dependencies specific to that environment.\n",
        "\n",
        "  \n",
        "\n",
        "#### Data dependency\n",
        "\n",
        "Steps required to setup the runtime environment on Colab are as follows:\n",
        "\n",
        " - Download the code from Github (run without change)\n",
        " - Import the project code (run without change).    \n",
        " - Download and unzip the dataset from Drive\n",
        "\n",
        "**Note**: The third step is specific to user and environment as it depends on accessing Google Drive. The file `params.py` under the project code directory `conf` will have to be customized.\n",
        "\n",
        "#### To Run\n",
        "- Resolve step 3 (above) for your environment. \n",
        "- Download the DeepWeeds data from here:\n",
        "  [images.zip](https://drive.google.com/file/d/1xnK3B6K6KekDI55vwJ0vnc2IGoDga9cj) (468 MB)\n",
        "- Execute `Run All` in Colab. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "import os.path\n",
        "import time\n",
        "from datetime import datetime\n",
        "import glob \n",
        "import shutil\n",
        "import pickle\n",
        "import copy\n",
        "import pathlib\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn.metrics as sm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torch.utils.data import RandomSampler, random_split\n",
        "from torch.utils.data import SubsetRandomSampler, WeightedRandomSampler\n",
        "from torchvision.datasets import ImageFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pbxKpG6s9vK"
      },
      "source": [
        "### Download the code from Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YZMmT0PtCog",
        "outputId": "7b990a66-048a-4e99-b36f-53e6b6171540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading file...\n",
            "--2022-03-29 22:06:09--  https://github.com/geraldmc/torch-draft-final_project/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/geraldmc/torch-draft-final_project/zip/refs/heads/main [following]\n",
            "--2022-03-29 22:06:09--  https://codeload.github.com/geraldmc/torch-draft-final_project/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 52.193.111.178\n",
            "Connecting to codeload.github.com (codeload.github.com)|52.193.111.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [ <=>                ] 526.76K  2.65MB/s    in 0.2s    \n",
            "\n",
            "2022-03-29 22:06:11 (2.65 MB/s) - ‘main.zip’ saved [539403]\n",
            "\n",
            "/content/torch-draft-final_project-main\n"
          ]
        }
      ],
      "source": [
        "if os.path.isfile(\"../main.zip\"):\n",
        "  print ('Have already downloaded the project file, continuing...')\n",
        "  print()\n",
        "else:\n",
        "  print ('Downloading file...')\n",
        "  ! wget https://github.com/geraldmc/torch-draft-final_project/archive/refs/heads/main.zip\n",
        "  ! unzip -qq main.zip\n",
        "  %cd torch-draft-final_project-main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "  import conf.params as params\n",
        "  from data import transforms as tsf\n",
        "  from data.test_loader import DeepWeeds_Test\n",
        "except ImportError:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVFrg7wPtJnj"
      },
      "source": [
        "### Download the dataset from Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTiLUTS_tUYp",
        "outputId": "bc228ab8-39b0-4f19-a12c-d8f1ee348aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Downloading DeepWeeds images to /content/torch-draft-final_project-main/data/images.zip\n",
            "\n",
            "-rw------- 1 root root 491516047 Mar 29 22:07 /content/torch-draft-final_project-main/data/images.zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "print()\n",
        "print(\"Downloading DeepWeeds images to \" + params.IMG_ZIP_FILE)\n",
        "!cp '{params.GD_ZIP_IMG}' '{params.IMG_ZIP_FILE}'\n",
        "print()\n",
        "!ls -lart {params.IMG_ZIP_FILE}\n",
        "\n",
        "print()\n",
        "print(\"Downloading GAN images to \" + params.GAN_ZIP_FILE)\n",
        "!cp '{params.GD_ZIP_GAN}' '{params.GAN_ZIP_FILE}'\n",
        "print()\n",
        "!ls -lart {params.GAN_ZIP_FILE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unzip the data files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"[INFO] Unzipping DeepWeeds images into \" +  params.IMG_DIRECTORY)\n",
        "\n",
        "with ZipFile(params.IMG_ZIP_FILE, \"r\") as zip_ref:\n",
        "  zip_ref.extractall(params.IMG_DIRECTORY)\n",
        "\n",
        "img_list=os.listdir(params.IMG_DIRECTORY)\n",
        "print(len(img_list))\n",
        "\n",
        "print()\n",
        "print(\"[INFO] Unzipping GAN image dirs into \" + params.DATA_PATH)\n",
        "\n",
        "with ZipFile(params.GAN_ZIP_FILE, \"r\") as zip_ref:\n",
        "  zip_ref.extractall(params.DATA_PATH)\n",
        "\n",
        "gan_dir_list=os.listdir(params.DATA_PATH+'/gans/train/0')\n",
        "print(len(gan_dir_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOQZnKZBtlMa",
        "outputId": "9c511545-0a56-40d7-c028-0c28fc9f33c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels.csv\t  test_subset3.csv   train_subset2.csv\tval_subset1.csv\n",
            "test_subset0.csv  test_subset4.csv   train_subset3.csv\tval_subset2.csv\n",
            "test_subset1.csv  train_subset0.csv  train_subset4.csv\tval_subset3.csv\n",
            "test_subset2.csv  train_subset1.csv  val_subset0.csv\tval_subset4.csv\n"
          ]
        }
      ],
      "source": [
        "LABEL_PATH = os.path.join(params.DATA_PATH, 'labels')\n",
        "label_df = pd.read_csv(os.path.join(LABEL_PATH, 'labels.csv'))\n",
        "None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Steps For Train and Evaluate\n",
        "\n",
        "##### 0) Get files in order (mainly Colab-specific).\n",
        "\n",
        "    1) Instantiate new data loaders.\n",
        "    2) Init a new ResNet50 model.\n",
        "    3) Get/set the parameters to be optimized/updated.\n",
        "    4) Train the model. Save the best model.\n",
        "    5) Delete contents of the train/val directories.\n",
        "    6) REPEAT 1-6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1) Supporting functions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0) Functions for Colab - getting train, test, val files in place."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_file_list():\n",
        "  files = []\n",
        "  for dirpath, dirnames, filenames in os.walk(params.IMAGE_PATH):\n",
        "    for file in filenames:\n",
        "      files.append(file)\n",
        "  return files\n",
        "\n",
        "def copy_files(df, files, filepath):\n",
        "  labels = dict(zip(df.Filename, df.Label)) \n",
        "  for f in files:\n",
        "    try:\n",
        "      src = os.path.join(params.IMG_DIRECTORY, f)\n",
        "      dst = os.path.join(filepath, str(labels[f]), f)\n",
        "      shutil.copyfile(src, dst)\n",
        "    except KeyError:\n",
        "      pass\n",
        "\n",
        "def delete_train_val_files(path):\n",
        "  for sub_dir in sorted(os.listdir(path)):\n",
        "    for file_name in os.listdir(os.path.join(path, sub_dir)):\n",
        "      file = os.path.join(path, sub_dir, file_name)\n",
        "      if os.path.isfile(file):\n",
        "        os.remove(file)\n",
        "\n",
        "def copy_test_files(df, filepath):\n",
        "  for f in df.Filename:\n",
        "    try:\n",
        "      src = os.path.join(params.IMG_DIRECTORY, f)\n",
        "      dst = os.path.join(filepath, f)\n",
        "      shutil.copyfile(src, dst)\n",
        "    except KeyError:\n",
        "      pass\n",
        "\n",
        "def delete_test_files(path):\n",
        "  for file_name in os.listdir(params.IMG_TEST_PATH):\n",
        "    file = os.path.join(path, file_name)\n",
        "    if os.path.isfile(file):\n",
        "      os.remove(file)\n",
        "\n",
        "def get_dataloader_counts(dl):\n",
        "  from collections import Counter\n",
        "  try:\n",
        "    train_dict = dict(Counter(\n",
        "      dl['train'].dataset.datasets[0].targets))\n",
        "    val_dict = dict(Counter(\n",
        "      dl['val'].dataset.datasets[0].targets))\n",
        "  except AttributeError:\n",
        "    #print('error')\n",
        "    train_dict = dict(Counter(\n",
        "      dl['train'].dataset.targets))\n",
        "    val_dict = dict(Counter(\n",
        "      dl['val'].dataset.targets))\n",
        " \n",
        "  return train_dict, val_dict\n",
        "\n",
        "def pickler(a, filename):\n",
        "  with open(filename+'.pickle', 'wb') as handle:\n",
        "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def unpickler(filename):\n",
        "  with open(filename, 'rb') as handle:\n",
        "    b = pickle.load(handle)\n",
        "  return b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ### 1a) Prepare single data loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_single_dataloader(batch_size):\n",
        "  '''Creates train and validation datasets and dataloaders.\n",
        "  The default transform is applied to each. See data/transforms.py.\n",
        "  '''\n",
        "  train_data_single = ImageFolder(\n",
        "    root=params.IMG_TRAIN_PATH, \n",
        "    transform=tsf.base_transform)\n",
        "  train_loader_single = DataLoader(train_data_single, \n",
        "    batch_size=batch_size, shuffle=True, \n",
        "    num_workers=2,\n",
        "    pin_memory=torch.cuda.is_available())\n",
        "\n",
        "  val_data_single = ImageFolder(\n",
        "    root=params.IMG_VAL_PATH, \n",
        "    transform=tsf.base_transform)\n",
        "  val_loader_single = DataLoader(val_data_single, \n",
        "    batch_size=batch_size, shuffle=False, \n",
        "    num_workers=2,\n",
        "    pin_memory=torch.cuda.is_available())\n",
        "\n",
        "  dataloaders_gan = {}\n",
        "  dataloaders_gan['train'] = train_loader_single\n",
        "  dataloaders_gan['val'] = val_loader_single\n",
        "\n",
        "  return dataloaders_gan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ### 1b) Prepare DeepWeeds augmented data loader (version 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_DW_dataloaders1(batch_size):\n",
        "  '''Creates train and validation datasets and dataloaders.\n",
        "  The default, hvflip and transform and jitter_hue transfroms \n",
        "  are applied. Triples the number of samples in each. \n",
        "  See data/transforms.py.\n",
        "  '''\n",
        "  # Each training dataset contains 8382 x 3 images.\n",
        "  # Shuffle is True for train, False for val.\n",
        "\n",
        "  train_loader_aug = DataLoader(\n",
        "  ConcatDataset([ImageFolder(\n",
        "      params.IMG_TRAIN_PATH, \n",
        "      transform=tsf.data_transforms['default']),\n",
        "    ImageFolder(\n",
        "      params.IMG_TRAIN_PATH,\n",
        "      transform=tsf.data_transforms['hvflip']),\n",
        "    ImageFolder(\n",
        "      params.IMG_TRAIN_PATH,\n",
        "      transform=tsf.data_transforms['jitter_hue'])]), \n",
        "      batch_size=batch_size, \n",
        "      shuffle=True, num_workers=2, \n",
        "      pin_memory=torch.cuda.is_available())\n",
        "\n",
        "  # Each validation dataset contains 3251 x 3 images.\n",
        "\n",
        "  val_loader_aug = DataLoader(\n",
        "  ConcatDataset([ImageFolder(\n",
        "      params.IMG_VAL_PATH, \n",
        "      transform=tsf.data_transforms['default']),\n",
        "    ImageFolder(\n",
        "      params.IMG_VAL_PATH,\n",
        "      transform=tsf.data_transforms['hvflip']),\n",
        "    ImageFolder(\n",
        "      params.IMG_VAL_PATH,\n",
        "      transform=tsf.data_transforms['jitter_hue'])]), \n",
        "      batch_size=batch_size, \n",
        "      shuffle=False, num_workers=2, # shuffle is False for val!\n",
        "      pin_memory=torch.cuda.is_available())\n",
        "\n",
        "  dataloaders_aug = {}\n",
        "  dataloaders_aug['train'] = train_loader_aug\n",
        "  dataloaders_aug['val'] = val_loader_aug\n",
        "\n",
        "  #print(\"Cumulative length of train:\", dataloaders_aug['train'].dataset.cumulative_sizes)\n",
        "  #print(\"Cumulative length of val:\", dataloaders_aug['val'].dataset.cumulative_sizes)\n",
        "\n",
        "  return dataloaders_aug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ### 1c) Prepare DeepWeeds augmented data loader (version 2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_DW_dataloaders2(batch_size):\n",
        "  '''Creates train and validation datasets and dataloaders.\n",
        "  The hvflip, default, ImageNet_autoaug and jitter_hue transfroms \n",
        "  are applied. Triples the number of samples in each. \n",
        "  See data/transforms.py.\n",
        "  '''\n",
        "\n",
        "  train_loader_aug = DataLoader(\n",
        "  ConcatDataset([ImageFolder(\n",
        "      params.IMG_TRAIN_PATH, \n",
        "      transform=tsf.data_transforms['hvflip']),\n",
        "    ImageFolder(\n",
        "      params.IMG_VAL_PATH,\n",
        "      transform=tsf.data_transforms['default']),\n",
        "    ImageFolder(\n",
        "      params.IMG_TRAIN_PATH,\n",
        "      transform=tsf.data_transforms['ImageNet_autoaug']),\n",
        "    ImageFolder(\n",
        "      params.IMG_TRAIN_PATH,\n",
        "      transform=tsf.data_transforms['jitter_hue'])]), \n",
        "      batch_size=batch_size, \n",
        "      shuffle=True, num_workers=2, \n",
        "      pin_memory=torch.cuda.is_available())\n",
        "\n",
        "  # Each validation dataset contains 3251 x 4 images.\n",
        "\n",
        "  val_loader_aug = DataLoader(\n",
        "  ConcatDataset([ImageFolder(\n",
        "      params.IMG_VAL_PATH, \n",
        "      transform=tsf.data_transforms['hvflip']),\n",
        "    ImageFolder(\n",
        "      params.IMG_VAL_PATH,\n",
        "      transform=tsf.data_transforms['default']),\n",
        "    ImageFolder(\n",
        "      params.IMG_VAL_PATH,\n",
        "      transform=tsf.data_transforms['ImageNet_autoaug']),\n",
        "    ImageFolder(\n",
        "      params.IMG_VAL_PATH,\n",
        "      transform=tsf.data_transforms['jitter_hue'])]), \n",
        "      batch_size=batch_size, \n",
        "      shuffle=False, num_workers=2, # shuffle is False for val!\n",
        "      pin_memory=torch.cuda.is_available())\n",
        "\n",
        "  dataloaders_aug = {}\n",
        "  dataloaders_aug['train'] = train_loader_aug\n",
        "  dataloaders_aug['val'] = val_loader_aug\n",
        "\n",
        "  #print(\"Cumulative length of train:\", dataloaders_aug['train'].dataset.cumulative_sizes)\n",
        "  #print(\"Cumulative length of val:\", dataloaders_aug['val'].dataset.cumulative_sizes)\n",
        "\n",
        "  return dataloaders_aug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ### 1b) Prepare combined data loaders (DeepWeed images, with GANs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_comb_dataloaders(transform_method='original'):\n",
        "  '''Creates combined train and validation datasets and dataloaders.\n",
        "  See data/transforms.py.\n",
        "  '''\n",
        "  \n",
        "  GAN_TRAIN_PATH = os.path.join(params.DATA_PATH, 'gans/train')\n",
        "\n",
        "  image_list = []\n",
        "\n",
        "  if transform_method == 'original':\n",
        "    image_list.append(ImageFolder(\n",
        "      root=GAN_TRAIN_PATH, \n",
        "      transform=tsf.data_transforms['original']))\n",
        "    image_list.append(ImageFolder(\n",
        "      root=params.IMG_TRAIN_PATH, \n",
        "      transform=tsf.data_transforms['original']))\n",
        "\n",
        "  elif transform_method == 'random':\n",
        "    image_list.append(ImageFolder(\n",
        "      root=GAN_TRAIN_PATH, \n",
        "      transform=tsf.data_transforms['random_augment']))\n",
        "    image_list.append(ImageFolder(\n",
        "      root=params.IMG_TRAIN_PATH, \n",
        "      transform=tsf.data_transforms['random_augment']))\n",
        "\n",
        "  elif transform_method == 'auto':\n",
        "    image_list.append(ImageFolder(\n",
        "      root=GAN_TRAIN_PATH, \n",
        "      transform=tsf.data_transforms['ImageNet_autoaug']))\n",
        "    image_list.append(ImageFolder(\n",
        "      root=params.IMG_TRAIN_PATH, \n",
        "      transform=tsf.data_transforms['ImageNet_autoaug']))\n",
        "\n",
        "  elif transform_method == 'grayscale':\n",
        "    image_list.append(ImageFolder(\n",
        "      root=GAN_TRAIN_PATH, \n",
        "      transform=tsf.data_transforms['grayscale']))\n",
        "    image_list.append(ImageFolder(\n",
        "      root=params.IMG_TRAIN_PATH, \n",
        "      transform=tsf.data_transforms['grayscale']))\n",
        "\n",
        "  elif transform_method == 'translate':\n",
        "    image_list.append(ImageFolder(\n",
        "      root=GAN_TRAIN_PATH, \n",
        "      transform=tsf.data_transforms['translate']))\n",
        "    image_list.append(ImageFolder(\n",
        "      root=params.IMG_TRAIN_PATH, \n",
        "      transform=tsf.data_transforms['translate']))\n",
        "  else:\n",
        "      pass #FIXME, handle this somehow\n",
        "\n",
        "\n",
        "  image_datasets = ConcatDataset(image_list)\n",
        "\n",
        "  img_sets = dict()\n",
        "  img_sets['train'], img_sets['val'] = random_split(image_datasets, \n",
        "                                      (round(0.8*len(image_datasets)), \n",
        "                                      round(0.2*len(image_datasets))))\n",
        "\n",
        "  combined_train_loader = DataLoader(img_sets['train'], \n",
        "                                  batch_size=32, shuffle=True, \n",
        "                                  num_workers=2)\n",
        "\n",
        "  combined_val_loader = DataLoader(img_sets['val'], \n",
        "                                  batch_size=32, shuffle=True, \n",
        "                                  num_workers=2)\n",
        "  dataloaders = {}\n",
        "  dataloaders['train'] = combined_train_loader\n",
        "  dataloaders['val'] = combined_val_loader\n",
        "\n",
        "  return dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Init a new ResNet50 model.\n",
        "\n",
        "Steps:\n",
        "  1) If feature extracting then set the required parameters.\n",
        "  2) If model other than ReNet, must set manually (for now). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    '''Sets required network params for feature extraction only. \n",
        "    '''\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract):\n",
        "  '''This will download a pretrained ResNet50 model and\n",
        "  alter it to suit the number of classes in our dataset. \n",
        "  '''\n",
        "    # Init a new ResNet50 model (called below)\n",
        "  model_ft = None\n",
        "  input_size = 0\n",
        "  if model_name == \"resnet50\":\n",
        "    \"\"\" Resnet50\n",
        "    \"\"\"\n",
        "    model_ft = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    input_size = 224\n",
        "  else:\n",
        "    print(\"Invalid model name, exiting...\")\n",
        "    exit()\n",
        "\n",
        "  return model_ft, input_size\n",
        "\n",
        "def init_model():\n",
        "  '''Init model\n",
        "  '''\n",
        "  model, input_size = initialize_model('resnet50', params.NUM_CLASSES, \n",
        "                                          feature_extract=True)\n",
        "  if torch.cuda.is_available():\n",
        "    model.to('cuda') #IMPORTANT!\n",
        "  \n",
        "  return model, input_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get/set the parameters to be optimized/updated for each k-fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_parameters(model, features):\n",
        "  '''  Only parameters that we've just initialized, i.e. the parameters with \n",
        "  requires_grad is True, are updated. (i.e. the last fc layer).\n",
        "  '''\n",
        "\n",
        "  params_to_update = model.parameters()\n",
        "\n",
        "  print(\"[INFO] Params to learn:\")\n",
        "  if features:\n",
        "    params_to_update = []\n",
        "    for name,param in model.named_parameters():\n",
        "      if param.requires_grad == True:\n",
        "        params_to_update.append(param)\n",
        "        print(\"\\t\",name)\n",
        "  else:\n",
        "    for name,param in model.named_parameters():\n",
        "      if param.requires_grad == True:\n",
        "        print(\"\\t\",name)\n",
        "  \n",
        "  print()\n",
        "\n",
        "  # Observe that all parameters are optimized\n",
        "  # optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
        "  opt = optim.Adam(params_to_update, lr=1e-3)\n",
        "  sch = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "      opt, patience=16, factor=0.5, min_lr=0.00003125)\n",
        "\n",
        "  return opt, sch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train and evaluate the model in one pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "    .                       o8o\n",
        "  .o8                       `\"'\n",
        ".o888oo oooo d8b  .oooo.   oooo  ooo. .oo.\n",
        "  888   `888\"\"8P `P  )88b  `888  `888P\"Y88b\n",
        "  888    888      .oP\"888   888   888   888\n",
        "  888 .  888     d8(  888   888   888   888\n",
        "  \"888\" d888b    `Y888\"\"8o o888o o888o o888o\n",
        "'''\n",
        "\n",
        "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs):\n",
        "  '''Function to train and validate concurrently. \n",
        "  '''\n",
        "  since = time.time()\n",
        "\n",
        "  # lists to store per-epoch loss and accuracy values\n",
        "  val_acc_history, val_loss_history = [], []\n",
        "  train_acc_history, train_loss_history = [], []\n",
        "\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  best_acc = 0.0\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print('\\t[INFO] Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('\\t' + '-' * 16)\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "      if phase == 'train':\n",
        "        model.train()  # Set model to training mode\n",
        "      else:\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "      running_loss = 0.0\n",
        "      running_corrects = 0\n",
        "\n",
        "      # Iterate over data.\n",
        "      for inputs, labels in dataloaders[phase]:\n",
        "        inputs = inputs.to(params.DEVICE)\n",
        "        labels = labels.to(params.DEVICE)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward\n",
        "        # track history if only in train\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          # Get model outputs and calculate loss\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          _, preds = torch.max(outputs, 1)\n",
        "\n",
        "          # backward + optimize only if in training phase\n",
        "          if phase == 'train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "          #else: # val mode\n",
        "              #scheduler.step(loss) # optimizer to scheduler for eval\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "      epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "      epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "      print('\\t{} loss: {:.4f} acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "      # deep copy the model\n",
        "      if phase == 'val' and epoch_acc > best_acc:\n",
        "        best_acc = epoch_acc\n",
        "        best_model_wts = copy.deepcopy(model.state_dict())\n",
        "      if phase == 'val':\n",
        "        val_acc_history.append(epoch_acc)\n",
        "        val_loss_history.append(epoch_loss)\n",
        "      elif phase == 'train':\n",
        "        train_acc_history.append(epoch_acc)\n",
        "        train_loss_history.append(epoch_loss)\n",
        "    print()\n",
        "  time_elapsed = time.time() - since\n",
        "  print('[INFO] Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "  print('[INFO] Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "  # load best model weights\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model, val_acc_history, val_loss_history, train_acc_history, train_loss_history, best_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions to kick off training/eval and to save resulting model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, dataloaders, optimizer, scheduler, epochs):\n",
        "  '''Function to call train/eval during each fold.\n",
        "  '''\n",
        "  criterion = nn.CrossEntropyLoss() # (i.e. binary_crossentropy)\n",
        "  model, va, vl, ta, tl, best_acc = train_model(model, dataloaders, criterion, \n",
        "                                                optimizer, scheduler, num_epochs=epochs)\n",
        "  return model, va, vl, ta, tl, best_acc\n",
        "\n",
        "def save_model(m, name):\n",
        "  '''Save model as a state dictionary. \n",
        "  '''\n",
        "  # provide a timestamp\n",
        "  timestamp = datetime.fromtimestamp(time.time()).strftime('%Y%m%d-%H%M%S')\n",
        "  saved_name = os.path.join(params.OUTPUT_PATH, str(timestamp) + name + '_model.pth')\n",
        "  torch.save(m.state_dict(), saved_name)\n",
        "  return saved_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to make accuracy and loss plots. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_plots(va, vl, ta, tl):\n",
        "  '''Plot train/val loss and accuracy\n",
        "  '''\n",
        "  # filenames to save plots\n",
        "  timestamp = datetime.fromtimestamp(time.time()).strftime('%Y%m%d-%H%M%S')\n",
        "  ta_va = 'ta_va_' + timestamp\n",
        "  tl_vl = 'tl_vl_' + timestamp\n",
        "  ta_tl = 'ta_tl_' + timestamp\n",
        "  va_vl = 'va_vl_' + timestamp\n",
        "\n",
        "  # Convert tensor objects to lists\n",
        "  val_acc_record = [va[x].item() for x in range(len(va))]\n",
        "  val_loss_record = [vl[x] for x in range(len(vl))]\n",
        "  train_acc_record = [ta[x].item() for x in range(len(ta))]\n",
        "  train_loss_record = [tl[x] for x in range(len(tl))]\n",
        "  \n",
        "  # Accuracy plots\n",
        "  plt.figure(figsize=(6, 4))\n",
        "  plt.plot(train_acc_record, color='green', label='train acc')\n",
        "  plt.plot(val_acc_record, color='blue', label='val acc')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.savefig(f\"output/{ta_va}.png\")\n",
        "  #plt.show()\n",
        "\n",
        "  # Loss plots\n",
        "  plt.figure(figsize=(6, 4))\n",
        "  plt.plot(train_loss_record, color='orange', label='train loss')\n",
        "  plt.plot(val_loss_record, color='red', label='val loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(f\"output/{tl_vl}.png\")\n",
        "  #plt.show()\n",
        "\n",
        "  # Train acc versus loss\n",
        "  plt.figure(figsize=(6, 4))\n",
        "  plt.plot(train_acc_record, color='blue', label='train acc')\n",
        "  plt.plot(train_loss_record, color='green', label='train loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy/Loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(f\"output/{ta_tl}.png\")\n",
        "  #plt.show()\n",
        "\n",
        "  # Val acc versus loss\n",
        "  plt.figure(figsize=(6, 4))\n",
        "  plt.plot(val_acc_record, color='red', label='val acc')\n",
        "  plt.plot(val_loss_record, color='orange', label='val loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy/Loss')\n",
        "  plt.legend()\n",
        "  plt.savefig(f\"output/{va_vl}.png\")\n",
        "  #plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to run k-folds. The default is 5. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_train_kfold(loader, batch):\n",
        "  '''Run kfolds on training. Fold images are loaded from a csv file. \n",
        "  '''\n",
        "  files = get_file_list()\n",
        "  best_epoch_accs = []\n",
        "\n",
        "  # K-fold cross validation, saving outputs for each fold.\n",
        "  for idx in range(params.FOLDS):\n",
        "      \n",
        "    timestamp = datetime.fromtimestamp(time.time()).strftime('%Y%m%d-%H%M%S')\n",
        "    print()\n",
        "    print('[INFO] Fold {}/{} - {}'.format(idx + 1, params.FOLDS, timestamp))\n",
        "    output_directory = \"{}/{}/\".format(params.OUTPUT_PATH, timestamp)\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "\n",
        "    train_label_file = \"{}/train_subset{}.csv\".format(LABEL_PATH, idx)\n",
        "    val_label_file = \"{}/val_subset{}.csv\".format(LABEL_PATH, idx)\n",
        "\n",
        "    train_df = pd.read_csv(train_label_file)\n",
        "    val_df = pd.read_csv(val_label_file)\n",
        "\n",
        "    copy_files(train_df, files, params.IMG_TRAIN_PATH)\n",
        "    copy_files(val_df, files, params.IMG_VAL_PATH)\n",
        "\n",
        "    if loader == '_no_aug':\n",
        "      deepweeds = get_single_dataloader(batch)\n",
        "    elif loader == '_aug1':\n",
        "      deepweeds = get_DW_dataloaders1(batch)\n",
        "    elif loader == '_aug2':\n",
        "      deepweeds = get_DW_dataloaders2(batch)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    # Stats for the datasets. \n",
        "    train_dict, val_dict = {},{}\n",
        "    train_dict, val_dict = get_dataloader_counts(deepweeds)\n",
        "\n",
        "    print()\n",
        "    print('[{}/{}] Train Class Distribution: {}'.format(idx + 1, \n",
        "                                            params.FOLDS, train_dict))\n",
        "\n",
        "    print('[{}/{}] Val Class Distribution: {}'.format(idx + 1, \n",
        "                                            params.FOLDS, val_dict))\n",
        "    print()\n",
        "    torch_resnet50, input_size = init_model()\n",
        "    optimizer, scheduler = get_parameters(torch_resnet50, features=True)\n",
        "\n",
        "    best_model_wts, va, vl, ta, tl, best_acc = train(torch_resnet50, deepweeds, \n",
        "                                                      optimizer, scheduler, 2)\n",
        "    saved_name = save_model(best_model_wts, loader)\n",
        "    best_epoch_accs.append(best_acc) \n",
        "    make_plots(va, vl, ta, tl)\n",
        "\n",
        "    # Assure that files are reset -----------------------------------\n",
        "    assert len(os.listdir(params.IMG_TRAIN_PATH + '/0')) != 0\n",
        "    delete_train_val_files(params.IMG_TRAIN_PATH)\n",
        "    assert len(os.listdir(params.IMG_TRAIN_PATH + '/0')) == 0\n",
        "    delete_train_val_files(params.IMG_VAL_PATH)\n",
        "    assert len(os.listdir(params.IMG_VAL_PATH + '/0')) == 0\n",
        "\n",
        "  return best_epoch_accs, saved_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run K-folds. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------ RUN TRAIN/EVAL ------------------------------------\n",
        "batch = 32\n",
        "best_fold_accs, saved_name = run_train_kfold('_no_aug', batch)\n",
        "# ----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save the current model on Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def copy_pth_to_gdrive(path_to_model):\n",
        "  '''Get the name of the model created above and save the current trained model to G Drive.\n",
        "  (This is optional)\n",
        "  '''\n",
        "  shutil.copy(path_to_model, params.GD_WRITE_DIR)\n",
        "  \n",
        "copy_pth_to_gdrive(saved_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Steps For Test\n",
        "##### 0) Get files in order (mainly Colab-specific).\n",
        "\n",
        "    1) Copy files to single directory (not using ImageFolder).\n",
        "    2) Instantiate data loaders.\n",
        "    3) Load the trained ResNet50 model.\n",
        "    4) Test the model. Save results.\n",
        "    5) Delete contents of the test directory.\n",
        "    7) REPEAT 1-5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Functions for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def return_last_pth():\n",
        "  '''Load the last model saved\n",
        "  '''\n",
        "  filename = max([f for f in pathlib.Path(params.OUTPUT_PATH).glob('*_model.pth')],\n",
        "                key=os.path.getctime)\n",
        "  return filename\n",
        "\n",
        "def print_states(m):\n",
        "  # Print the model's state_dict\n",
        "  print(\"Model's state_dict:\")\n",
        "  for param_tensor in m.state_dict():\n",
        "    print(param_tensor, \"\\t\", m.state_dict()[param_tensor].size())\n",
        "\n",
        "def load_model(name):\n",
        "  '''Load a trained model for testing. \n",
        "  '''\n",
        "  model, input_size = init_model()\n",
        "  model.load_state_dict(torch.load(name))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function to test the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.metrics as sm\n",
        "\n",
        "'''\n",
        "    .                          .\n",
        "  .o8                        .o8\n",
        "888oo  .ooooo.   .oooo.o .o888oo\n",
        "  888   d88' `88b d88(  \"8   888\n",
        "  888   888ooo888 `\"Y88b.    888\n",
        "  888 . 888    .o o.  )88b   888 .\n",
        "  \"888\" `Y8bod8P' 8\"\"888P'   \"888\"\n",
        "'''\n",
        "\n",
        "def test(test_loader, model):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  targets, preds = [], []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      if torch.cuda.is_available():\n",
        "        data = data.cuda()\n",
        "        target = target.cuda()\n",
        "      output = model(data)\n",
        "      pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "      targets += list(target.cpu().numpy())\n",
        "      preds += list(pred.cpu().numpy())\n",
        "  \n",
        "  test_acc = 100. * correct / len(test_loader.dataset)\n",
        "  confusion_mtx = sm.confusion_matrix(targets, preds)\n",
        "  return test_acc, confusion_mtx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run k-folds in testing also."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_test_kfold(model):\n",
        "  ''' Runs 5 folds (set in params file).\n",
        "  '''\n",
        "  \n",
        "  metrics = {}\n",
        "\n",
        "  for idx in range(params.FOLDS):\n",
        "    test_label_file = \"{}/test_subset{}.csv\".format(LABEL_PATH, idx)\n",
        "    test_df = pd.read_csv(test_label_file)\n",
        "    copy_test_files(test_df, params.IMG_TEST_PATH)\n",
        "\n",
        "    test_dataset = DeepWeeds_Test(test_label_file)\n",
        "    test_loader  = DataLoader(test_dataset, \n",
        "      batch_size=params.BATCH_SIZE, shuffle=False,\n",
        "      pin_memory=torch.cuda.is_available(), \n",
        "      num_workers=2)\n",
        "\n",
        "    # --- Get metrics for each fold.\n",
        "    metrics[idx] = test(test_loader, model)\n",
        "    # ---\n",
        "\n",
        "    delete_test_files(params.IMG_TEST_PATH)\n",
        "    cnt = len([name for name in os.listdir(params.IMG_TEST_PATH) \\\n",
        "              if os.path.isfile(os.path.join(params.IMG_TEST_PATH, name))])\n",
        "    assert cnt == 0\n",
        "  \n",
        "  return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = load_model(saved_name)\n",
        "results = run_test_kfold(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save the results of testing and plot a confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stamp = saved_name.split('_')[0].split('/')[1]\n",
        "pickle_name = 'results_'+stamp\n",
        "pickler(results, pickle_name)\n",
        "\n",
        "# Pick out the best of five confusion matrixes, i.e. cm = results[2][1]\n",
        "cmd = sm.ConfusionMatrixDisplay(results[0][1], display_labels=['0','1','2','3','4','5','6','7','8'])\n",
        "cmd.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate other metrics. Note: From here down was included AFTER handing in the assignment! \n",
        "file = '/content/torch-draft-final_project-main/output/results_20220426-184852.pickle'\n",
        "result = unpickler(file)\n",
        "mtx = result[4][1]\n",
        "\n",
        "FP = mtx.sum(axis=0) - np.diag(mtx) \n",
        "FN = mtx.sum(axis=1) - np.diag(mtx)\n",
        "TP = np.diag(mtx)\n",
        "TN = mtx.sum() - (FP + FN + TP)\n",
        "FP = FP.astype(float)\n",
        "FN = FN.astype(float)\n",
        "TP = TP.astype(float)\n",
        "TN = TN.astype(float)\n",
        "\n",
        "# Sensitivity, hit rate, recall, or true positive rate\n",
        "TPR = TP/(TP+FN)\n",
        "# Specificity or true negative rate\n",
        "TNR = TN/(TN+FP) \n",
        "# Precision or positive predictive value\n",
        "PPV = TP/(TP+FP)\n",
        "# Negative predictive value\n",
        "NPV = TN/(TN+FN)\n",
        "# Fall out or false positive rate\n",
        "FPR = FP/(FP+TN)\n",
        "# False negative rate\n",
        "FNR = FN/(TP+FN)\n",
        "# False discovery rate\n",
        "FDR = FP/(TP+FP)\n",
        "# Overall accuracy for each class\n",
        "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "#df = pd.DataFrame({'count': {'0':0.8,'1':0.85377358,'2':0.98543689,'3':0.89705882,\n",
        "#                             '4':0.94811321,'5':0.9427363,'6':0.91588785,'7':0.89655172,\n",
        "#                             '8':0.94618342 }}).reset_index()\n",
        "#plt.bar(range(len(df)), df[\"count\"], color=plt.cm.Paired(np.arange(len(df))))\n",
        "\n",
        "#None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_bar_plot(metric):\n",
        "  ''' Plot Sensitivity/Recall\n",
        "  '''\n",
        "  keys = ['0', '1', '2', '3', '4', '5', '6', '7', '8']\n",
        "  values = [round(x, 2) for x in metric.tolist()]\n",
        "  test_dict = dict(zip(keys, values))\n",
        "\n",
        "  df = pd.DataFrame({'count': test_dict}).reset_index()\n",
        "  plt.bar(range(len(df)), df[\"count\"], color=plt.cm.Paired(np.arange(len(df))))\n",
        "  None\n",
        "  return test_dict\n",
        "\n",
        "test_dict = make_bar_plot(TPR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "sns.histplot(label_df['Label'], bins=8, discrete=True, color=\"lightcoral\")\n",
        "None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### fin"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNakgWdfr0oHr8HQcRFOsFM",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "load_deepweeds.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "bio39",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "9028ef67598a7b8b240cccd1bef3a2fae76776f81d3d1f95bdd4ea94e797c2bd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
