{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "271431d0",
   "metadata": {},
   "source": [
    "### Data Augmentation with imgaug\n",
    "\n",
    "Using the following library, we increased the datasets (each class by 2)\n",
    "\n",
    "https://github.com/aleju/imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "955eab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "import PIL\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a55e2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['image.interpolation'] = 'nearest'\n",
    "mpl.rcParams['figure.figsize'] = 8, 16\n",
    "\n",
    "def save_dataset(dataset, n=1):\n",
    "    for i in range (len(dataset)):\n",
    "        img = dataset[i][0]\n",
    "        img_name = f\"data/tran_dataaug/train_0/0/generate_00{i}.jpg\"\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08a7033f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and 1 > 0) else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64644ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rashe\\anaconda3\\lib\\site-packages\\imgaug\\imgaug.py:184: DeprecationWarning: Function `SimplexNoiseAlpha()` is deprecated. Use `BlendAlphaSimplexNoise` instead. SimplexNoiseAlpha is deprecated. Use BlendAlphaSimplexNoise instead. The order of parameters is the same. Parameter 'first' was renamed to 'foreground'. Parameter 'second' was renamed to 'background'.\n",
      "  warn_deprecated(msg, stacklevel=3)\n",
      "C:\\Users\\rashe\\anaconda3\\lib\\site-packages\\imgaug\\imgaug.py:184: DeprecationWarning: Function `FrequencyNoiseAlpha()` is deprecated. Use `BlendAlphaFrequencyNoise` instead. FrequencyNoiseAlpha is deprecated. Use BlendAlphaFrequencyNoise instead. The order of parameters is the same. Parameter 'first' was renamed to 'foreground'. Parameter 'second' was renamed to 'background'.\n",
      "  warn_deprecated(msg, stacklevel=3)\n"
     ]
    }
   ],
   "source": [
    "img_size = 224\n",
    "#original data\n",
    "dataroot = \"data/train/\"\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "class ImgAugTransform:\n",
    "    def __init__(self, ):\n",
    "        self.aug = iaa.Sequential([\n",
    "#         # apply the following augmenters to most images\n",
    "#         iaa.Fliplr(0.5).copy(), # horizontally flip 50% of all images\n",
    "#         iaa.Flipud(0.2).copy(), # vertically flip 20% of all images\n",
    "        # crop images by -5% to 10% of their height/width\n",
    "        sometimes(iaa.CropAndPad(\n",
    "            percent=(-0.05, 0.1),\n",
    "            pad_mode=ia.ALL,\n",
    "            pad_cval=(0, 255)\n",
    "        )),\n",
    "        sometimes(iaa.Affine(\n",
    "            scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}, # scale images to 80-120% of their size, individually per axis\n",
    "            translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}, # translate by -20 to +20 percent (per axis)\n",
    "            rotate=(-45, 45), # rotate by -45 to +45 degrees\n",
    "            shear=(-16, 16), # shear by -16 to +16 degrees\n",
    "            order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
    "            cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
    "            mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
    "        )),\n",
    "        # execute 0 to 5 of the following (less important) augmenters per image\n",
    "        # don't execute all of them, as that would often be way too strong\n",
    "        iaa.SomeOf((0, 5),\n",
    "            [\n",
    "                sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
    "                iaa.OneOf([\n",
    "                    iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\n",
    "                    iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                    iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                ]),\n",
    "                iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
    "                iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
    "                # search either for all edges or for directed edges,\n",
    "                # blend the result with the original image using a blobby mask\n",
    "                iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "                    iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
    "                    iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
    "                ])),\n",
    "                iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
    "                iaa.OneOf([\n",
    "                    iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "                    iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n",
    "                ]),\n",
    "                iaa.Invert(0.05, per_channel=True), # invert color channels\n",
    "                iaa.Add((-10, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                iaa.AddToHueAndSaturation((-20, 20)), # change hue and saturation\n",
    "                # either change the brightness of the whole image (sometimes\n",
    "                # per channel) or change the brightness of subareas\n",
    "                iaa.OneOf([\n",
    "                    iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
    "                    iaa.FrequencyNoiseAlpha(\n",
    "                        exponent=(-4, 0),\n",
    "                        first=iaa.Multiply((0.5, 1.5), per_channel=True),\n",
    "                        second=iaa.LinearContrast((0.5, 2.0))\n",
    "                    )\n",
    "                ]),\n",
    "                iaa.LinearContrast((0.5, 2.0), per_channel=0.5), # improve or worsen the contrast\n",
    "                iaa.Grayscale(alpha=(0.0, 1.0)),\n",
    "                sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
    "                sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
    "                sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
    "            ],\n",
    "            random_order=True\n",
    "        )\n",
    "    ],\n",
    "    random_order=True\n",
    ")\n",
    "      \n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        return self.aug.augment_image(img)\n",
    "\n",
    "# transforms = ImgAugTransform()\n",
    "\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               ImgAugTransform(),\n",
    "#                                transforms.RandomHorizontalFlip(),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60cbfd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate NX data for each class \n",
    "#file is saved in a different directory\n",
    "kfolds = 1\n",
    "for k in range(kfolds):\n",
    "    for i, z in zip(range(len(dataset)), dataset.targets):\n",
    "        img = dataset[i][0]\n",
    "        img_name = f\"data/train_dataaug/train/{z}/generated_{k}000{i}.jpg\"\n",
    "        save_image(img, img_name, nrow=1, normalize=True)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "9028ef67598a7b8b240cccd1bef3a2fae76776f81d3d1f95bdd4ea94e797c2bd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
